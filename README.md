# FlexoZero YAML ëª¨ë¸ ë ˆí¬ì§€í† ë¦¬

> **YAML ê¸°ë°˜ ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¹Œë” - AutoBuilder**
> íŒŒì´ì¬ ì½”ë“œë¥¼ ì§ì ‘ ìˆ˜ì •í•˜ì§€ ì•Šê³ ë„ ë‹¤ì–‘í•œ ì‹ ê²½ë§ ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„, í•™ìŠµ, ê³µìœ í•  ìˆ˜ ìˆëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

---

## âœ¨ ì£¼ìš” íŠ¹ì§•

| ê¸°ëŠ¥ | ì„¤ëª… |
| --- | --- |
| **YAML ê¸°ë°˜ ëª¨ë¸ ì •ì˜** | ë‹¨ì¼ YAML íŒŒì¼ë§Œìœ¼ë¡œ ë³µì¡í•œ ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ì •ì˜ - ë ˆì´ì–´ ìˆœì„œ, ë°˜ë³µ, ì±„ë„ ìˆ˜, í™œì„±í™” í•¨ìˆ˜, ì •ê·œí™”ê¹Œì§€ ì„¤ì • ê°€ëŠ¥ |
| **YOLO ìŠ¤íƒ€ì¼ ë¬¸ë²•** | `[from, n, module, *args, {kwargs}]` í˜•íƒœì˜ ì§ê´€ì ì¸ íŠœí”Œ ë¬¸ë²•ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ëª¨ë¸ êµ¬ì¡° í‘œí˜„ |
| **ë™ì  ìŠ¤ì¼€ì¼ë§** | `depth_multiple`, `width_multiple` íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ í¬ê¸°ë¥¼ ì‰½ê²Œ ì¡°ì ˆ |
| **ë‹¤ì–‘í•œ ë¸”ë¡ ì§€ì›** | ConvBlock, LinearBlock, GlobalAvgPool, TransformerEncoderBlock ë“± ê¸°ë³¸ ë¸”ë¡ ì œê³µ |
| **ìë™ ë°ì´í„°ì…‹ ì²˜ë¦¬** | MNIST, CIFAR10 ë“± í‘œì¤€ ë°ì´í„°ì…‹ì„ ìœ„í•œ DataLoader í†µí•© |
| **GPU ê°€ì†** | CUDA ì§€ì›ìœ¼ë¡œ ë¹ ë¥¸ í•™ìŠµ ë° ì¶”ë¡  ì„±ëŠ¥ |
| **PyTorch í˜¸í™˜** | PyTorch í…ì„œì™€ í•¨ê»˜ ì‚¬ìš© ê°€ëŠ¥í•œ ìœ ì—°í•œ í™•ì¥ì„± |

---

## ğŸ“¦ ì„¤ì¹˜

**Python â‰¥ 3.8** ë° **NumPy** í•„ìš” (PyTorch í…ì„œ ì§€ì› ì„ íƒì )

```bash
# ë ˆí¬ì§€í† ë¦¬ ë³µì œ
git clone https://github.com/yourusername/flexozero.git
cd flexozero

# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™” (ì„ íƒ ì‚¬í•­)
python -m venv venv
.\venv\Scripts\activate  # Windows

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

1. **YAML ëª¨ë¸ ì„¤ì •íŒŒì¼ ì‘ì„±** (`configs/` ë””ë ‰í† ë¦¬ì˜ ì˜ˆì œ ì°¸ê³ )
2. **ëª¨ë¸ ìƒì„± ë° í•™ìŠµ**

   ```python
   import flexo
   from flexo.autobuilder import YamlModel
   
   # YAML íŒŒì¼ì—ì„œ ëª¨ë¸ ìƒì„±
   model = YamlModel('configs/vgg16.yaml')
   
   # ë°ì´í„° ì¤€ë¹„
   train_loader = flexo.DataLoader(flexo.datasets.MNIST(train=True), batch_size=32)
   
   # í•™ìŠµ ë£¨í”„
   for epoch in range(10):
       for x, t in train_loader:
           y = model(x)
           loss = F.softmax_cross_entropy(y, t)
           model.cleargrads()
           loss.backward()
           optimizer.update()
   ```

3. **í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰**

   ```bash
   # ì˜ˆì œ VGG16 ëª¨ë¸ë¡œ MNIST í•™ìŠµ
   python vgg16_mnist.py
   ```

4. **ëª¨ë¸ ì •ë³´ í™•ì¸**

   ```bash
   # ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ë³´ ì¶œë ¥
   python model_info.py
   ```

---

## ğŸ“ YAML ëª¨ë¸ ì •ì˜ í˜•ì‹

```yaml
# vgg16.yaml - MNISTìš© ê°„ì†Œí™”ëœ VGG16 ëª¨ë¸ ì˜ˆì œ

# ê¸°ë³¸ ì„¤ì •
in_channels: 1          # ì…ë ¥ ì±„ë„ ìˆ˜ (MNISTëŠ” í‘ë°± ì´ë¯¸ì§€)
num_classes: 10         # ì¶œë ¥ í´ë˜ìŠ¤ ìˆ˜
input_size: [28, 28]    # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°

# ìŠ¤ì¼€ì¼ë§ ì¸ì
depth_multiple: 1.0     # ë ˆì´ì–´ ë°˜ë³µ íšŸìˆ˜ ë°°ìœ¨
width_multiple: 0.5     # ì±„ë„ ìˆ˜ ë°°ìœ¨ (ì‘ì€ ëª¨ë¸)

# ë ˆì´ì–´ ì •ì˜ [from, repeat, block_type, out_channels, kernel_size, stride, {params}]
layers:
  # Block 1
  - [-1, 1, ConvBlock, 64, 3, 1, {act: relu, norm: bn}]   # Conv1_1
  - [-1, 1, ConvBlock, 64, 3, 1, {act: relu, norm: bn}]   # Conv1_2
  - [-1, 1, ConvBlock, 64, 2, 2, {act: relu}]             # MaxPool1

  # Block 2
  - [-1, 1, ConvBlock, 128, 3, 1, {act: relu, norm: bn}]  # Conv2_1
  
  # íŠ¹ì„± í‰íƒ„í™” (Flatten)
  - [-1, 1, GlobalAvgPool, 0]                           # ì „ì—­ í‰ê·  í’€ë§
  
  # ì™„ì „ ì—°ê²° ë ˆì´ì–´ (FC)
  - [-1, 1, LinearBlock, 512, 0, 0, {act: relu, drop: 0.5}]   # FC1
  - [-1, 1, LinearBlock, 10, 0, 0, {}]                        # ì¶œë ¥ ë ˆì´ì–´
```

### YAML í•„ë“œ ì„¤ëª…

| í•„ë“œ | íƒ€ì… | ì„¤ëª… |
| --- | --- | --- |
| **from** | `int` | ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•  ì´ì „ ë ˆì´ì–´ ì¸ë±ìŠ¤ (-1 = ì§ì „ ë ˆì´ì–´) |
| **repeat** | `int` | ë¸”ë¡ ë°˜ë³µ íšŸìˆ˜ (`depth_multiple`ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •) |
| **block_type** | `str` | ë¸”ë¡ ìœ í˜• (ConvBlock, LinearBlock, GlobalAvgPool ë“±) |
| **out_channels** | `int` | ì¶œë ¥ ì±„ë„ ìˆ˜ (ConvBlock) ë˜ëŠ” ì¶œë ¥ íŠ¹ì„± ìˆ˜ (LinearBlock) |
| **kernel_size** | `int` | ì»¤ë„ í¬ê¸° (ConvBlockì—ë§Œ ì ìš©) |
| **stride** | `int` | ìŠ¤íŠ¸ë¼ì´ë“œ (ConvBlockì—ë§Œ ì ìš©) |
| **params** | `dict` | ì„ íƒì  ë§¤ê°œë³€ìˆ˜ (í™œì„±í™” í•¨ìˆ˜, ì •ê·œí™”, ë“œë¡­ì•„ì›ƒ ë“±) |

#### ì§€ì›ë˜ëŠ” í™œì„±í™” í•¨ìˆ˜ (`act`)
`relu`, `silu`, `sigmoid`, `tanh` ë“±

#### ì •ê·œí™” ì˜µì…˜ (`norm`)
`bn` (BatchNormalization), `ln` (LayerNormalization)

---

## ğŸ”§ ì»¤ìŠ¤í…€ ë¸”ë¡ ì¶”ê°€

ìƒˆë¡œìš´ ë¸”ë¡ì„ ì¶”ê°€í•˜ë ¤ë©´ `flexo/blocks.py`ì— í´ë˜ìŠ¤ë¥¼ ì •ì˜í•˜ê³  ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡í•˜ì„¸ìš”:

```python
class MyCustomBlock(Model):
    def __init__(self, in_features, out_features, **kwargs):
        super().__init__()
        # ë¸”ë¡ êµ¬í˜„
        
    def forward(self, x):
        # ìˆœì „íŒŒ êµ¬í˜„
        return output

# ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡
BLOCK_REGISTRY['MyCustomBlock'] = MyCustomBlock
```

YAML íŒŒì¼ì—ì„œ ìƒˆ ë¸”ë¡ ì‚¬ìš©:
```yaml
- [-1, 1, MyCustomBlock, 256, {custom_param: value}]
```

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
â”œâ”€ flexo/                # í•µì‹¬ í”„ë ˆì„ì›Œí¬ ì½”ë“œ
â”‚  â”œâ”€ autobuilder.py     # YAML ëª¨ë¸ ë¹Œë”
â”‚  â”œâ”€ blocks.py          # ë¸”ë¡ ì •ì˜ ë° ë ˆì§€ìŠ¤íŠ¸ë¦¬
â”‚  â”œâ”€ core.py            # ë³€ìˆ˜, í•¨ìˆ˜, ì—­ì „íŒŒ ë“± í•µì‹¬ ê¸°ëŠ¥
â”‚  â”œâ”€ cuda.py            # GPU ì§€ì› ê¸°ëŠ¥
â”‚  â”œâ”€ functions.py       # ìˆ˜í•™ í•¨ìˆ˜ ë° ì—°ì‚°
â”‚  â”œâ”€ layers.py          # ê¸°ë³¸ ë ˆì´ì–´ ì •ì˜
â”‚  â””â”€ models.py          # ëª¨ë¸ ê¸°ë³¸ í´ë˜ìŠ¤
â”œâ”€ configs/              # YAML ëª¨ë¸ ì •ì˜
â”œâ”€ model_info.py         # ëª¨ë¸ ì •ë³´ ì¶œë ¥
â””â”€ vgg16_mnist.py        # VGG16-MNIST í•™ìŠµ ì˜ˆì œ
```

---

## ğŸ“Š êµ¬í˜„ëœ ì˜ˆì œ ëª¨ë¸

* **VGG16**: MNIST ë°ì´í„°ì…‹ì— ìµœì í™”ëœ VGG16 ëª¨ë¸ (`configs/vgg16.yaml`)
* **ResNet**: ê°„ì†Œí™”ëœ ResNet ì•„í‚¤í…ì²˜ (`configs/resnet.yaml`)
* **VAE**: Variational Autoencoder êµ¬í˜„ (`configs/vae.yaml`)

---

## ğŸ™ ê°ì‚¬ì˜ ê¸€

ì´ í”„ë¡œì íŠ¸ëŠ” [Chainer](https://github.com/chainer/chainer), [PyTorch](https://pytorch.org/), [YOLOv5](https://github.com/ultralytics/yolov5)ì— ì˜ê°ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.
