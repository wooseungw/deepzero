training:
  optimizer: Adam
  loss: CrossEntropyLoss
  epochs: 50
  batch_size: 32
  learning_rate: 0.001
  checkpoint_interval: 5
  log_dir: './logs'
